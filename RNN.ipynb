{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEat6Rac8SUryFltVWXtMb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marybello/RNN-NLP/blob/master/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH-GHrSiwjKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ec1432a1-5a3d-4337-bf8f-7f14a44d21cd"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvFguPgS4cbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "114f817d-274b-4880-f727-dae7cde081e3"
      },
      "source": [
        "vocab_size = 88584\n",
        "maxlen = 250\n",
        "batch_size = 64\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=vocab_size)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpgOxsgV5I6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#because our data are is not equal\n",
        "train_data = sequence.pad_sequences(train_data, maxlen)\n",
        "test_data = sequence.pad_sequences(test_data, maxlen)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FeyoFae6Y9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model= tf.keras.Sequential([\n",
        "                            tf.keras.layers.Embedding(vocab_size,32),\n",
        "                            tf.keras.layers.LSTM(32),\n",
        "                            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "                           \n",
        "                       \n",
        "])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmHGpBBh6cFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "1666a2a5-00f4-4995-c635-aeefb4468cc7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 32)          2834688   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,843,041\n",
            "Trainable params: 2,843,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEoA7r7Q7fn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "c1db95b7-8e94-457f-8212-12c11d6872f0"
      },
      "source": [
        "#compile and train our model\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='rmsprop',\n",
        "    metrics=['acc']\n",
        ")\n",
        "model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.4153 - acc: 0.8106 - val_loss: 0.2975 - val_acc: 0.8822\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 38s 60ms/step - loss: 0.2364 - acc: 0.9114 - val_loss: 0.3086 - val_acc: 0.8850\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 38s 60ms/step - loss: 0.1788 - acc: 0.9331 - val_loss: 0.2704 - val_acc: 0.8948\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 38s 60ms/step - loss: 0.1492 - acc: 0.9456 - val_loss: 0.2803 - val_acc: 0.8832\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 37s 60ms/step - loss: 0.1257 - acc: 0.9560 - val_loss: 0.3385 - val_acc: 0.8772\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 37s 60ms/step - loss: 0.1071 - acc: 0.9632 - val_loss: 0.3459 - val_acc: 0.8774\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 38s 60ms/step - loss: 0.0978 - acc: 0.9679 - val_loss: 0.3585 - val_acc: 0.8868\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 38s 60ms/step - loss: 0.0821 - acc: 0.9729 - val_loss: 0.3205 - val_acc: 0.8798\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 38s 60ms/step - loss: 0.0726 - acc: 0.9765 - val_loss: 0.3382 - val_acc: 0.8874\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 38s 60ms/step - loss: 0.0686 - acc: 0.9790 - val_loss: 0.4619 - val_acc: 0.8822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fca01886128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma2n7ce-8Tup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "1f1d4840-428d-4bd2-abdd-e6e60c0ae8ec"
      },
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 12s 16ms/step - loss: 0.5984 - acc: 0.8429\n",
            "[0.5983681082725525, 0.8429200053215027]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ErViwre88_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "7d341811-6f03-448c-c713-255f934ddcf0"
      },
      "source": [
        "from tensorflow import keras\n",
        "word_index = imdb.get_word_index()\n",
        "def encode_text(text):\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return sequence.pad_sequences([tokens],maxlen)[0]\n",
        "text = 'that movie was just so amazing, so amazing'\n",
        "encoded = encode_text(text)\n",
        "encoded  \n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  12,  17,  13,  40,  35,\n",
              "       477,  35, 477], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5dTcWcl_HbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac36120c-9d63-49a3-d693-e8685fbc0e22"
      },
      "source": [
        "reverse_word_index = {value: key for (key,value) in word_index.items()}\n",
        " \n",
        "def decode_integer(integers):\n",
        "  pad = 0\n",
        "  text =\"\"\n",
        "  for num in integers:\n",
        "    if num != pad:\n",
        "      text += reverse_word_index[num] + ' '\n",
        "  return text[:-1]    \n",
        "print(decode_integer(encoded))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that movie was just so amazing so amazing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSkDOPqcA7kA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ede2eb7f-db3a-4e3e-f3ea-7d6f9379dbc0"
      },
      "source": [
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0]  = encoded_text\n",
        "  result = model.predict(pred)\n",
        "  print(result[0])\n",
        "positive_review =\"The movie was totally awesome, i really loved it and i would watch it again beacue it was great\"\n",
        "predict(positive_review)  \n",
        "negative_review = \"The movie really sucked, i hated it and i would not watch it again because it's one of the worst movies i've seen\"\n",
        "predict(negative_review)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.53148574]\n",
            "[0.5001014]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGN9zbq5EM_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating a model that is capable of predicting the next character in a  sequence\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF_hWQExEww9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "f6814c41-c709-4975-fc34-81fdfa78edfe"
      },
      "source": [
        "path_to_file = keras.utils.get_file('shakespear.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OThnrHkOF5-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to select your own file from your computer\n",
        "#from google.colab import files\n",
        "#path_to_file = list(files.upload().keys())[0]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFFBheTAGmGb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42d3c0a0-7b0c-415d-da69-da7b99a9c38e"
      },
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print('length of text is {} characters'.format(len(text)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of text is 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1kYRpxmHGyC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "9a06db8e-3e7e-4d9b-8842-9d7eeb78e231"
      },
      "source": [
        "text[:250]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEJmc260HU2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "db67c4f4-9ae1-4db1-8d02-b026a347264c"
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "#creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i,u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "text_as_int = text_to_int(text)\n",
        "print(\"Text\", text[:13])\n",
        "text_to_int(text[:13])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text First Citizen\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4qhPMjkK2yy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d1f8f178-16ab-471b-b52e-971d0624deea"
      },
      "source": [
        "#writing an opposite function\n",
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx2char[ints])\n",
        "print(int_to_text([6,53,54,23,4,5,1,45,22,3,26,26]))      "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ",opK&' gJ$NN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9TtfGhrMFJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "#Create training examples\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFjCeRr2MrNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences= char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8KQQ3J1M8Ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "dataset = sequences.map(split_input_target)  "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIlooJXmNncC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "outputId": "0a3b8c84-6eb0-4a15-ba91-abc90e21d59b"
      },
      "source": [
        "for x,y in dataset.take(2):\n",
        "  print('\\n\\nExample\\n')\n",
        "  print('INPUT')\n",
        "  print(int_to_text(x))\n",
        "  print('\\n OUTPUT')\n",
        "  print(int_to_text(y))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Example\n",
            "\n",
            "INPUT\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "\n",
            " OUTPUT\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "\n",
            "\n",
            "Example\n",
            "\n",
            "INPUT\n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "\n",
            " OUTPUT\n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLA1OnMhO1Ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "vocab_size = len(vocab)\n",
        "embedding = 256\n",
        "rnn_units = 1024\n",
        "buffer_size =10000\n",
        "data = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJDl8Ny9PoIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "636e6a19-022c-4e47-d93f-e7be1dd7856f"
      },
      "source": [
        "def build_model(vocab_size,embedding,rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Embedding(vocab_size,embedding, batch_input_shape=[batch_size,None]),\n",
        "                               tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True,recurrent_initializer='glorot_uniform'),\n",
        "                               tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "model = build_model(vocab_size,embedding,rnn_units, batch_size)\n",
        "model.summary()  "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aHsBVhxRgRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eff0b2f4-28b2-41ba-e8cd-dbead8adc2e3"
      },
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT-xwIXIW0ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rENh0SUbXFFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss=loss)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH4Nf6roXdS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir,'ckpt_{epoch}')\n",
        "checkpoint_callback= tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAOu_-KWYX7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f7486b9-077a-4075-9253-bbf13580678f"
      },
      "source": [
        "history = model.fit(data,epochs=40,callbacks=[checkpoint_callback])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 2.7589\n",
            "Epoch 2/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 2.0972\n",
            "Epoch 3/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 1.8426\n",
            "Epoch 4/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 1.6724\n",
            "Epoch 5/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 1.5555\n",
            "Epoch 6/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 1.4768\n",
            "Epoch 7/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 1.4191\n",
            "Epoch 8/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 1.3743\n",
            "Epoch 9/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 1.3368\n",
            "Epoch 10/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 1.3037\n",
            "Epoch 11/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 1.2725\n",
            "Epoch 12/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 1.2427\n",
            "Epoch 13/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 1.2129\n",
            "Epoch 14/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 1.1830\n",
            "Epoch 15/40\n",
            "172/172 [==============================] - 28s 164ms/step - loss: 1.1511\n",
            "Epoch 16/40\n",
            "172/172 [==============================] - 28s 164ms/step - loss: 1.1193\n",
            "Epoch 17/40\n",
            "172/172 [==============================] - 28s 164ms/step - loss: 1.0862\n",
            "Epoch 18/40\n",
            "172/172 [==============================] - 28s 163ms/step - loss: 1.0502\n",
            "Epoch 19/40\n",
            "172/172 [==============================] - 28s 163ms/step - loss: 1.0147\n",
            "Epoch 20/40\n",
            "172/172 [==============================] - 28s 164ms/step - loss: 0.9776\n",
            "Epoch 21/40\n",
            "172/172 [==============================] - 28s 163ms/step - loss: 0.9397\n",
            "Epoch 22/40\n",
            "172/172 [==============================] - 28s 164ms/step - loss: 0.9018\n",
            "Epoch 23/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 0.8646\n",
            "Epoch 24/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 0.8287\n",
            "Epoch 25/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 0.7950\n",
            "Epoch 26/40\n",
            "172/172 [==============================] - 28s 166ms/step - loss: 0.7627\n",
            "Epoch 27/40\n",
            "172/172 [==============================] - 28s 166ms/step - loss: 0.7313\n",
            "Epoch 28/40\n",
            "172/172 [==============================] - 28s 166ms/step - loss: 0.7023\n",
            "Epoch 29/40\n",
            "172/172 [==============================] - 29s 166ms/step - loss: 0.6757\n",
            "Epoch 30/40\n",
            "172/172 [==============================] - 29s 166ms/step - loss: 0.6501\n",
            "Epoch 31/40\n",
            "172/172 [==============================] - 28s 166ms/step - loss: 0.6278\n",
            "Epoch 32/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 0.6066\n",
            "Epoch 33/40\n",
            "172/172 [==============================] - 29s 166ms/step - loss: 0.5876\n",
            "Epoch 34/40\n",
            "172/172 [==============================] - 28s 165ms/step - loss: 0.5706\n",
            "Epoch 35/40\n",
            "172/172 [==============================] - 28s 166ms/step - loss: 0.5536\n",
            "Epoch 36/40\n",
            "140/172 [=======================>......] - ETA: 5s - loss: 0.5343"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSS8HqF1ZL_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size,embedding,rnn_units,batch_size=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_wZvxwoZkhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(tf.train_latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}